<html>
<head>
<title>Tian Theunissen</title>
<meta property="og:image" content="profile_fig.png" />
<link rel="stylesheet" href="style.css">
<style>

.papers li {
  margin: 10px 0;
}

.hl {
    background-color: rgb(255, 255, 208);
    /* list-style-position: inside; */
    padding: 5px;
}

p.quote {
    padding: 10px;
}

.container {
    display: flex;
    justify-content: center;
}
.main {
    /* border: 1px solid black; */
    max-width: 900px;
}

.columns {
    display: flex;
    /* padding: 30px; */
}

.column{
    /* margin-left: 30px; */
    margin-right: 30px;
}
.columnb {
    flex : 1;
    margin-right: 0px;
}
.columnc {
    flex : 1;
    margin-left: 20px;
}

header {
    /* border: 1px solid gray; */
    display: flex;
}
header .desc{
    margin-right: 30px;
    max-width: 400px;
}

.headshot {
    width: 256px;
    height: 256px;
    display:block;
    background: url("./profile_fig.png") no-repeat;
    background-size: 384px;
}
.headshot:hover {
    background: url("./profile_fig.png") no-repeat;
    background-size: 384px;
}
</style>

</head>
<body>


<div class="container">
<div class="main">

<header style="background-color: #fcc264 ;">
    <div class="column">
    <img src="./profile_fig.png" width="394px">
    </div>
    <div class="desc">
        <h1>Tian Theunissen</h1>
        I'm a PhD student studying generalization in deep learning.
		I was educated as a computer and electronic engineer and naturally drifted towards machine learning.

<p>
Some <b>simple questions</b> I ask myself: 
	Why do big neural networks generalize? 
	Does the bias-variance tradeoff need to be modified or replaced? 
	Do bigger neural networks actually perform better under early-stopping conditions? 
	Are neural networks just ensembles of cleverly fitted subpredictors?
	Why is there so little general theory on ensembling?
        <p>
        <a href="https://scholar.google.com/citations?user=p3bOWQEAAAAJ&hl=en">
            <b>[publications]</b></a>
            &emsp; &emsp;
        <a href="http://engineering.nwu.ac.za/must">
            <b>[group]</b></a>
            &emsp; &emsp;
		<a href="./resume.pdf">
            <b>[cv]</b></a>
            &emsp; &emsp;
        <code>tiantheunissen@gmail.com</code><br>
    </div>
</header>

<div class="row">
<hr>
<h2>
    My current goings-on:
</h2>
<ul>
<li>
	Late in 2020 I am writing up my thesis.
</li>
<li>
    Early in 2020 I went to AAAI in New York to present a paper we wrote in our research group.
</li>
<li>
	Late in 2019 I presented a paper at the first SACAIR conference in Cape Town, South Africa.
</li>
<li>
	Late in 2018 I presented some of my work at a workshop in Hermanus, South Africa.
</li>
</ul>
<hr>
</div>



<div class="columns">
<div class = "columnb">
<h2>Research</h2>
Without proven fundamental principles in machine learning we are forced to resort to heuristics and scientific rigor.
As a result I do a lot of experimenting on toy problems while making sure my assumptions are reasonable.
<p>
<!-- <h3>Noise and generalization</h3> -->
<ul class="papers">
	
	<li class="hl">
		<a><b>Benign interpolation of noise in deep learning</b></a><br>
		Marthinus W. Theunissen, Marelie H.Davel, Etienne Barnard
		<br>
		<i>To be published. Dec 2020</i>
	</li>
		
	<li>
		<a href="http://www.cair.org.za/sites/default/files/2020-01/theunissen-2019-insights-regarding-overfitting.pdf">
			<b>Insights regarding overfitting on noise in deep learning</b></a><br>
		Marthinus W. Theunissen, Marelie H.Davel, Etienne Barnard
		<br>
		<i>Published. 2019</i>
	</li>
		
	<li class="hl">
		<a href="https://arxiv.org/pdf/2001.06178.pdf">
			<b>DNNs as layers of cooperating classifiers</b></a><br>
		Marelie H.Davel, Marthinus W. Theunissen, Arnold M. Pretorius, Etienne Barnard
		<br>
		<i>Published. 2020</i>
	</li>
	
</ul>
</div>

<div class = "columnc">
<figure>
	<a href="http://www.cair.org.za/sites/default/files/2020-01/theunissen-2019-insights-regarding-overfitting.pdf">
		<img src="./generalization_and_noise.png", width=100%>
		<figcaption>Generalization and noise</figcaption>
	</a>
	</figure>

	<figure>
	<a href="https://arxiv.org/pdf/2001.06178.pdf">
		<img src="./layer_perplexity.png", width=100%>
		<figcaption>Perplexity and depth</figcaption>
	</a>
	</figure>

	<figure>
	<a href="./gauss_noise_sample_priority.png">
		<img src="./gauss_noise_sample_priority.png", width=100%>
		<figcaption>Noise and sample priority</figcaption>
	</a>
</figure>

<h2>About Me</h2>
I am South African.

<p>
	I intend to continue conducting academic research on topics of machine learning for as long as I am able.
</p>

<p>
	I believe that understanding why a system works (or doesn't) is infinitely more important than getting it to work.
</p>

		
</div>
</div>

</div>
</div>




</div>

</body>

</html>
